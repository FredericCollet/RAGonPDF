import os
import fitz  # PyMuPDF
import re
import nltk
import faiss
import pickle
from nltk.tokenize import sent_tokenize
from sentence_transformers import SentenceTransformer
from datetime import datetime

nltk.download('punkt_tab')

# üì• Dossier contenant les PDF
INPUT_FOLDER = "C:/Users/fred_/OneDrive/ML/ML-LLM/CONTRATOS/JEUX_REDUIT"
OUTPUT_FOLDER = "C:/users/fred_/OneDrive/ML/RAGonPDF/Text"
INDEX_PATH = "C:/Users/fred_/OneDrive/ML/RAGonPDF/Index_faiss"
LOG_FILE = "log.txt"

# ‚öôÔ∏è Param√®tres
CHUNK_SIZE = 500  # Taille des segments en caract√®res
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"  # Mod√®le pour les embeddings

# üîÑ Initialisation
nltk.download("punkt")
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
model = SentenceTransformer(EMBEDDING_MODEL)  # Charge le mod√®le d'embedding

# üîπ Cr√©ation de la base vectorielle FAISS
embedding_dim = model.get_sentence_embedding_dimension()
index = faiss.IndexFlatL2(embedding_dim)  # Index bas√© sur la distance L2
metadata = []  # Stocke les segments associ√©s aux embeddings

def clean_text(text):
    """ Nettoie le texte : suppression des espaces et des lignes inutiles. """
    text = re.sub(r"\s+", " ", text).strip()
    return text

def segment_text(text, chunk_size):
    """ Segmente le texte en morceaux de taille d√©finie. """
    sentences = sent_tokenize(text)
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= chunk_size:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks

# üìò Ouverture du fichier de log
log_file = open(LOG_FILE, "w", encoding="utf-8")

def log(msg):
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    full_msg = f"{timestamp} {msg}"
    print(full_msg)
    log_file.write(full_msg + "\n")

# üîç Parcours des PDF
for root, dirs, files in os.walk(INPUT_FOLDER):
    for filename in files:
        if filename.endswith(".pdf"):
            pdf_path = os.path.join(root, filename)
            relative_path = os.path.relpath(root, INPUT_FOLDER)
            output_dir = os.path.join(OUTPUT_FOLDER, relative_path)
            os.makedirs(output_dir, exist_ok=True)
            text_output_path = os.path.join(output_dir, filename.replace(".pdf", "_segments.txt"))


            # üö´ V√©rifie que le fichier n'est pas vide
            if os.path.getsize(pdf_path) == 0:
                log(f"‚ùå Fichier vide : {filename}, ignor√©.")
                continue

            try:
                doc = fitz.open(pdf_path)
            except Exception as e:
                log(f"‚ùå Erreur √† l'ouverture de {filename} : {e}")
                continue
            
            # üìù Extraction du texte
            doc = fitz.open(pdf_path)
            text = " ".join([page.get_text("text") for page in doc])

            # üîç Ignore les PDF vides
            if not text.strip():
                log(f"‚ö†Ô∏è {filename} est vide ou illisible.")
                continue

            # ‚ú® Nettoyage
            text = clean_text(text)

            # ‚úÇÔ∏è Segmentation
            chunks = segment_text(text, CHUNK_SIZE)

            if not chunks:
                log(f"‚ö†Ô∏è Aucun chunk trouv√© dans {filename}.")
                continue

            # üß† Conversion en embeddings et ajout √† FAISS
            chunk_embeddings = model.encode(chunks, convert_to_numpy=True)
            
            
             # üõ†Ô∏è Forcer la forme correcte si 1 seul chunk
            if len(chunk_embeddings.shape) == 1:
                chunk_embeddings = chunk_embeddings.reshape(1, -1)

            # üîç Debug
            log(f"üìê Embeddings shape pour {filename} : {chunk_embeddings.shape}")

            # üõ†Ô∏è Correction forme 1D
            if chunk_embeddings.ndim == 1:
                log(f"‚ÑπÔ∏è 1 seul embedding pour {filename}, reshape vers (1, -1).")
                chunk_embeddings = chunk_embeddings.reshape(1, -1)

            # üß± V√©rifie que c‚Äôest bien une matrice 2D
            if chunk_embeddings.ndim != 2:
                log(f"‚ùå Erreur : embeddings avec shape inattendue pour {filename}, ignor√©.")
                continue

            # üö´ V√©rifie que ce n‚Äôest pas vide
            if chunk_embeddings.shape[0] == 0:
                log(f"‚ö†Ô∏è Embeddings vides pour {filename}, fichier ignor√©.")
                continue
                      
            # ‚ûï Ajout √† FAISS
            index.add(chunk_embeddings)
            

            # üìå Stockage des m√©tadonn√©es
            metadata.extend([(filename, i, chunk) for i, chunk in enumerate(chunks)])

            # üìÇ Sauvegarde des segments
            with open(text_output_path, "w", encoding="utf-8") as text_file:
                for i, chunk in enumerate(chunks):
                    text_file.write(f"### Segment {i+1} ###\n{chunk}\n\n")

            log(f"üìÑ {filename} : texte segment√© et index√©.")


# üíæ Sauvegarde de l'index FAISS et des m√©tadonn√©es
faiss.write_index(index, os.path.join(INDEX_PATH, "faiss.index"))

with open(os.path.join(INDEX_PATH, "metadata.pkl"), "wb") as f:
    pickle.dump(metadata, f)

log("‚úÖ Indexation termin√©e et sauvegard√©e !")


# ‚úÖ Fermeture du fichier de log
log_file.close()
